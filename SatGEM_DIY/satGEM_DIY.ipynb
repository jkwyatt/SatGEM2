{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ca8187-132d-4880-b14e-711b8b2e1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copernicusmarine\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path  # NEW\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Path setup: make things relative to the repo\n",
    "# ============================================\n",
    "# Folder that contains THIS script\n",
    "HERE = Path(__file__).resolve().parent\n",
    "\n",
    "# If this script lives in the top-level of the repo, use:\n",
    "REPO_ROOT = HERE\n",
    "\n",
    "# If this script lives in a subfolder (e.g. SatGEM2/satGEM_DIY/build_satGEM.py),\n",
    "# then use the parent:\n",
    "# REPO_ROOT = HERE.parent\n",
    "\n",
    "# Default locations *inside the repo* (edit if you use different names)\n",
    "DEFAULT_CSV_PATH = REPO_ROOT / \"saved_adt_rel.csv\"        # or REPO_ROOT / \"data\" / \"saved_adt_rel.csv\"\n",
    "DEFAULT_TS_DIR = REPO_ROOT / \"ts_gem_fields\"              # folder with GEM_{lon}.nc\n",
    "DEFAULT_GAMMA_DIR = REPO_ROOT / \"gamma_gem_fields\"        # folder with GEM_{lon}_gamma_n.nc\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Helper: load slope / intercept for a longitude\n",
    "# ============================================\n",
    "def load_data_for_longitude(csv_path, target_longitude):\n",
    "    \"\"\"\n",
    "    Reads a CSV with columns: longitude, slope, intercept\n",
    "    and returns (slope, intercept) for the given target_longitude.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)  # ensure it's a Path\n",
    "\n",
    "    with csv_path.open('r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        # Skip the header row\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if len(row) < 3:\n",
    "                continue\n",
    "            longitude, slope, intercept = row\n",
    "            if float(longitude) == target_longitude:\n",
    "                try:\n",
    "                    slope = float(slope)\n",
    "                    intercept = float(intercept)\n",
    "                    return slope, intercept\n",
    "                except ValueError:\n",
    "                    # If conversion fails, return None for both slope and intercept\n",
    "                    return None, None\n",
    "    # If no matching longitude found\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Helper: parse dates (single date or range)\n",
    "# ============================================\n",
    "def parse_dates(dates):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      - \"2020-01-01\"\n",
    "      - (\"2020-01-01\", \"2020-01-10\")\n",
    "    Returns (start_str, end_str) suitable for Copernicus:\n",
    "      [start, end) in daily resolution.\n",
    "    \"\"\"\n",
    "    if isinstance(dates, str):\n",
    "        start = datetime.strptime(dates, \"%Y-%m-%d\")\n",
    "        end = start + timedelta(days=1)\n",
    "    elif isinstance(dates, (list, tuple)) and len(dates) == 2:\n",
    "        start = datetime.strptime(dates[0], \"%Y-%m-%d\")\n",
    "        end = datetime.strptime(dates[1], \"%Y-%m-%d\") + timedelta(days=1)\n",
    "    else:\n",
    "        raise ValueError(\"dates must be 'YYYY-MM-DD' or ('YYYY-MM-DD', 'YYYY-MM-DD').\")\n",
    "\n",
    "    return start.strftime(\"%Y-%m-%d\"), end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main function: build SatGEM fields\n",
    "# ============================================\n",
    "def build_satGEM_fields(\n",
    "    dates,\n",
    "    lon_min,\n",
    "    lon_max,\n",
    "    lat_min,\n",
    "    lat_max,\n",
    "    csv_path=None,\n",
    "    static_ts_dir=None,\n",
    "    static_gamma_dir=None,\n",
    "    dataset_id=\"c3s_obs-sl_glo_phy-ssh_my_twosat-l4-duacs-0.25deg_P1D\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Build SatGEM ts and gamma fields for a given date or date range,\n",
    "    longitude range, and latitude range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dates : str or (str, str)\n",
    "        Single date: \"2020-01-01\"\n",
    "        or date range: (\"2020-01-01\", \"2020-01-10\")\n",
    "    lon_min, lon_max : float\n",
    "        Longitude range in degrees (can be -180..180 or 0..360).\n",
    "    lat_min, lat_max : float\n",
    "        Latitude range in degrees.\n",
    "    csv_path : str or Path, optional\n",
    "        Path to CSV with (longitude, slope, intercept).\n",
    "        Defaults to CSV inside the repo.\n",
    "    static_ts_dir : str or Path, optional\n",
    "        Path to GEM_{lon}.nc files (T/S/dyn_m).\n",
    "        Defaults to ts_gem_fields/ inside the repo.\n",
    "    static_gamma_dir : str or Path, optional\n",
    "        Path to GEM_{lon}_gamma_n.nc files.\n",
    "        Defaults to gamma_gem_fields/ inside the repo.\n",
    "    dataset_id : str\n",
    "        Copernicus Marine SSH dataset ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    satGEM_ts_field : xr.Dataset\n",
    "        TS fields on the SSH grid (includes time dimension if multiple days).\n",
    "    satGEM_gamma_field : xr.DataArray\n",
    "        gamma_n on the SSH grid, regridded to a common pressure axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 0) Resolve default paths if not provided\n",
    "    # ----------------------------------------\n",
    "    if csv_path is None:\n",
    "        csv_path = DEFAULT_CSV_PATH\n",
    "    if static_ts_dir is None:\n",
    "        static_ts_dir = DEFAULT_TS_DIR\n",
    "    if static_gamma_dir is None:\n",
    "        static_gamma_dir = DEFAULT_GAMMA_DIR\n",
    "\n",
    "    csv_path = Path(csv_path)\n",
    "    static_ts_dir = Path(static_ts_dir)\n",
    "    static_gamma_dir = Path(static_gamma_dir)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1) Build slopes_intercepts dict (0–359)\n",
    "    # ----------------------------------------\n",
    "    slopes_intercepts = {}\n",
    "    for lon in range(-180, 180):\n",
    "        adjusted_lon = (lon + 360) % 360  # 0..359\n",
    "        slopes_intercepts[adjusted_lon] = load_data_for_longitude(csv_path, lon)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2) Parse dates for CopernicusMarine\n",
    "    # ----------------------------------------\n",
    "    start_str, end_str = parse_dates(dates)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3) Open SSH from Copernicus for date range\n",
    "    # ----------------------------------------\n",
    "    ssh = copernicusmarine.open_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        variables=[\"adt\"],\n",
    "        minimum_longitude=lon_min,\n",
    "        maximum_longitude=lon_max,\n",
    "        minimum_latitude=lat_min,\n",
    "        maximum_latitude=lat_max,\n",
    "        start_datetime=start_str,\n",
    "        end_datetime=end_str,\n",
    "    )\n",
    "\n",
    "    # Put longitude in [0, 360] and sort\n",
    "    ssh = ssh.assign_coords(\n",
    "        longitude=((ssh.longitude + 360) % 360)\n",
    "    ).sortby(\"longitude\")\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 4) Define longitude range in 0–360\n",
    "    # ----------------------------------------\n",
    "    def to_0360(lon):\n",
    "        return (lon + 360) % 360\n",
    "\n",
    "    lon_min_0360 = to_0360(lon_min)\n",
    "    lon_max_0360 = to_0360(lon_max)\n",
    "\n",
    "    def lon_in_range(lon_val):\n",
    "        \"\"\"Check if lon_val (0–360) lies within [lon_min, lon_max], allowing wrap.\"\"\"\n",
    "        if lon_min_0360 <= lon_max_0360:\n",
    "            return (lon_val >= lon_min_0360) and (lon_val <= lon_max_0360)\n",
    "        else:\n",
    "            # wrap-around case, e.g. lon_min=350, lon_max=10\n",
    "            return (lon_val >= lon_min_0360) or (lon_val <= lon_max_0360)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 5) Main loop over longitude steps\n",
    "    #    (time is handled implicitly by xarray)\n",
    "    # ----------------------------------------\n",
    "    satGEM_field = []\n",
    "    satGEM_gamma_field_list = []\n",
    "\n",
    "    for lon_step in tqdm(ssh.longitude.values, desc=\"Processing longitudes\"):\n",
    "\n",
    "        # Skip 0 exactly if desired, as in your original code\n",
    "        if lon_step == 0:\n",
    "            continue\n",
    "\n",
    "        # Restrict to requested longitude range\n",
    "        if not lon_in_range(lon_step):\n",
    "            continue\n",
    "\n",
    "        # SSH ±0.125° around current longitude (keeps time & lat dims)\n",
    "        ssh_insitu_bb = ssh.sel(\n",
    "            longitude=slice(lon_step - 0.125, lon_step + 0.125)\n",
    "        ).adt\n",
    "\n",
    "        # If everything is NaN here, skip\n",
    "        if np.all(np.isnan(ssh_insitu_bb)):\n",
    "            continue\n",
    "\n",
    "        # For GEM files: convert to -180..180\n",
    "        if lon_step > 180:\n",
    "            lon_access = lon_step - 360\n",
    "        else:\n",
    "            lon_access = lon_step\n",
    "\n",
    "        # Use floor for negative longitudes instead of int truncation\n",
    "        lon_file = int(np.floor(lon_access))\n",
    "\n",
    "        # Get slope/intercept from dict\n",
    "        slopes_key = int(np.floor(lon_step))  # 0..359\n",
    "        slope, intercept = slopes_intercepts.get(slopes_key, (None, None))\n",
    "        if slope is None or intercept is None or slope == 0:\n",
    "            continue\n",
    "\n",
    "        # File paths (now using Path)\n",
    "        t_s_file_path = static_ts_dir / f\"GEM_{lon_file}.nc\"\n",
    "        gamma_file_path = static_gamma_dir / f\"GEM_{lon_file}_gamma_n.nc\"\n",
    "\n",
    "        if not (t_s_file_path.exists() and gamma_file_path.exists()):\n",
    "            continue\n",
    "\n",
    "        # Open GEM fields\n",
    "        t_s_field = xr.open_dataset(t_s_file_path)\n",
    "        gamma_field = xr.open_dataset(gamma_file_path)\n",
    "        gamma_field['pressure'] = t_s_field['pressure']\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # 6) Map dyn_m -> SSH using linear fit\n",
    "        # ----------------------------------------\n",
    "        ssh_GEM = (t_s_field.dyn_m - intercept) / slope\n",
    "\n",
    "        # Put everything on 'ssh' instead of 'dyn_m'\n",
    "        t_s_field_ssh = (\n",
    "            t_s_field\n",
    "            .assign_coords(ssh=ssh_GEM)\n",
    "            .swap_dims({'dyn_m': 'ssh'})\n",
    "            .drop_vars('dyn_m')\n",
    "        )\n",
    "        gamma_field_ssh = (\n",
    "            gamma_field\n",
    "            .assign_coords(ssh=ssh_GEM)\n",
    "            .swap_dims({'dyn_m': 'ssh'})\n",
    "            .drop_vars('dyn_m')\n",
    "        )\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # 7) Interpolate GEM onto observed SSH\n",
    "        # ----------------------------------------\n",
    "        satGEM_ts_field_lon = t_s_field_ssh.sel(ssh=ssh_insitu_bb, method='nearest')\n",
    "        satGEM_ts_field_lon = satGEM_ts_field_lon.where(~np.isnan(ssh_insitu_bb), np.nan)\n",
    "\n",
    "        satGEM_gamma_lon = gamma_field_ssh['gamma_n'].sel(ssh=ssh_insitu_bb, method='nearest')\n",
    "        satGEM_gamma_lon = satGEM_gamma_lon.where(~np.isnan(ssh_insitu_bb), np.nan)\n",
    "\n",
    "        satGEM_field.append(satGEM_ts_field_lon)\n",
    "        satGEM_gamma_field_list.append(satGEM_gamma_lon)\n",
    "\n",
    "    if not satGEM_field:\n",
    "        raise RuntimeError(\"No SatGEM fields were created – check date / lon / lat ranges and data availability.\")\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 8) Concatenate TS fields along longitude\n",
    "    # ----------------------------------------\n",
    "    satGEM_ts_field = xr.concat(satGEM_field, dim='longitude')\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 9) Concatenate gamma, regridding pressure\n",
    "    # ----------------------------------------\n",
    "    all_pressures = np.unique(\n",
    "        np.concatenate([da['pressure'].values for da in satGEM_gamma_field_list])\n",
    "    )\n",
    "\n",
    "    gamma_regridded = [\n",
    "        da.reindex(pressure=all_pressures)\n",
    "        for da in satGEM_gamma_field_list\n",
    "    ]\n",
    "\n",
    "    satGEM_gamma_field = xr.concat(\n",
    "        gamma_regridded,\n",
    "        dim='longitude'\n",
    "    )\n",
    "\n",
    "    return satGEM_ts_field, satGEM_gamma_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa784a8-72b8-4d41-b24e-c9cd4f959b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-11-27T05:58:57Z - Selected dataset version: \"202411\"\n",
      "INFO:copernicusmarine:Selected dataset version: \"202411\"\n",
      "INFO - 2025-11-27T05:58:57Z - Selected dataset part: \"default\"\n",
      "INFO:copernicusmarine:Selected dataset part: \"default\"\n",
      "INFO - 2025-11-27T05:58:57Z - Downloading Copernicus Marine data requires a Copernicus Marine username and password, sign up for free at: https://data.marine.copernicus.eu/register\n",
      "INFO:copernicusmarine:Downloading Copernicus Marine data requires a Copernicus Marine username and password, sign up for free at: https://data.marine.copernicus.eu/register\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copernicus Marine username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  jwyatt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copernicus Marine password:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/jobfs/155457593.gadi-pbs/ipykernel_1697560/4197172656.py:244: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'pressure' ('pressure',) The recommendation is to set join explicitly for this case.\n",
      "  satGEM_ts_field = xr.concat(satGEM_field, dim='longitude')\n"
     ]
    }
   ],
   "source": [
    "# Date range\n",
    "ts_range, gamma_range = build_satGEM_fields(\n",
    "    dates=(\"2020-01-01\", \"2020-01-02\"),\n",
    "    lon_min=140, lon_max=150,\n",
    "    lat_min=-60, lat_max=-50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eeec7-001d-435f-8a88-b330864da1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
